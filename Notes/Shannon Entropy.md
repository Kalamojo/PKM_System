---
alias: []
subject: Data Science Intro
tags: [undergrad]
---
# Shannon Entropy

```ad-math
For an event $X$, with a number of possibilities with their designated probabilities, the entropy of the event $X$ is:
$$H(X)=-\sum_{i=1}^{n} p_{i} \log _{2} p_{i}$$
```

```ad-example
Normal coin flip: probability of heads is 0.5, probability of tails is 0.5.
- $-1*(0.5 * \log_2 0.5 + 0.5 * \log_2 0.5) =$
- $-1*(-0.5 + -0.5) = 1$
```

## References
1. [[Entropy]]
2. [[Probability]]