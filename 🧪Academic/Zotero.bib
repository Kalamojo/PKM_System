
@article{allam_2019,
  title = {Achieving {{Neuroplasticity}} in {{Artificial Neural Networks}} through {{Smart Cities}}},
  author = {Allam, Zaheer},
  date = {2019-04-08},
  journaltitle = {Smart Cities},
  volume = {2},
  number = {2},
  pages = {118--134},
  doi = {10.3390/smartcities2020009},
  abstract = {Through the Internet of things (IoT), as promoted by smart cities, there is an emergence of big data accentuating the use of artificial intelligence through various components of urban planning, management, and design. One such system is that of artificial neural networks (ANNs), a component of machine learning that boasts similitude with brain neurological networks and its functioning. However, the development of ANN was done in singular fashion, whereby processes are rendered in sequence in a unidimensional perspective, contrasting with the functions of the brain to which ANN boasts similitude, and in particular to the concept of neuroplasticity which encourages unique complex interactions in self-learning fashion, thereby encouraging more inclusive urban processes and render urban coherence. This paper takes inspiration from Christopher Alexander’s Nature of Order and dwells in the concept of complexity theory; it also proposes a theoretical model of how ANN can be rendered with the same plastic properties as brain neurological networks with multidimensional interactivity in the context of smart cities through the use of big data and its emerging complex networks. By doing so, this model caters to the creation of stronger, richer, and more complex patterns that support Alexander’s concept of “wholeness” through the connection of overlapping networks. This paper is aimed toward engineers with interdisciplinary interest looking at creating more complex and intricate ANN models, and toward urban planners and urban theorists working on the emerging contemporary concept of smart cities.},
  annotation = {MAG ID: 2929790092}
}

@article{arun.iyer_2020,
  title = {On the {{Analysis}} of {{COVID19}} - {{Novel Corona Viral Disease Pandemic Spread Data Using Machine Learning Techniques}}},
  author = {Arun, Shreyas Setlur and Iyer, Ganesh Neelakanta},
  date = {2020-05-01},
  journaltitle = {2020 4th International Conference on Intelligent Computing and Control Systems (ICICCS)},
  pages = {1222--1227},
  doi = {10.1109/iciccs48265.2020.9121027},
  abstract = {Coronaviruses are a group of viruses that cause various diseases in mammals and birds. In humans, they cause a range of respiratory disorders. This paper presents the analysis of the transmission of COVID19 disease and predicts the scale of the pandemic, the recovery rate as well as the fatality rate. We have used some of the well-known machine learning techniques as well as mathematical modeling techniques such as Rough Set-Support Vector Machine (RS-SVM), Bayesian Ridge and Polynomial Regression, SIR model, and RNN.},
  annotation = {MAG ID: 3036775350 S2ID: b55ee3774f4724467e93770d0034b087185a6afb}
}

@article{axelkowald.etal_2022,
  title = {Transfer Learning of Clinical Outcomes from Preclinical Molecular Data, Principles and Perspectives.},
  author = {{Axel Kowald} and {Israel Barrantes} and {Steffen Möller} and {Daniel Palmer} and {Hugo Murua Escobar} and {Anne Schwerk} and Fuellen, Georg},
  date = {2022-04-23},
  journaltitle = {Briefings in Bioinformatics},
  eprint = {35453145},
  eprinttype = {pmid},
  doi = {10.1093/bib/bbac133},
  abstract = {Accurate transfer learning of clinical outcomes from one cellular context to another, between cell types, developmental stages, omics modalities or species, is considered tremendously useful. When transferring a prediction task from a source domain to a target domain, what counts is the high quality of the predictions in the target domain, requiring states or processes common to both the source and the target that can be learned by the predictor reflected by shared denominators. These may form a compendium of knowledge that is learned in the source to enable predictions in the target, usually with few, if any, labeled target training samples to learn from. Transductive transfer learning refers to the learning of the predictor in the source domain, transferring its outcome label calculations to the target domain, considering the same task. Inductive transfer learning considers cases where the target predictor is performing a different yet related task as compared with the source predictor. Often, there is also a need to first map the variables in the input/feature spaces and/or the variables in the output/outcome spaces. We here discuss and juxtapose various recently published transfer learning approaches, specifically designed (or at least adaptable) to predict clinical (human in vivo) outcomes based on preclinical (mostly animal-based) molecular data, towards finding the right tool for a given task, and paving the way for a comprehensive and systematic comparison of the suitability and accuracy of transfer learning of clinical outcomes.},
  pmcid = {9116218},
  annotation = {MAG ID: 4224316211 S2ID: 1fafdd303a3b3619e16e625db046a4dcce8cb68c},
  file = {C\:\\Users\\nov18\\Dropbox\\PC\\Downloads\\axelkowald.etal_2022 - Annotations (962022, 103640 PM).md;C\:\\Users\\nov18\\Zotero\\storage\\56AEN8PB\\Axel Kowald et al_2022_Transfer learning of clinical outcomes from preclinical molecular data,.pdf}
}

@article{brubaker.etal_2019,
  title = {Computational {{Translation}} of {{Genomic Responses From Experimental Model Systems}} to {{Humans}}},
  author = {Brubaker, Douglas K. and Proctor, Elizabeth A. and Haigis, Kevin M. and Lauffenburger, Douglas A.},
  date = {2019-01-10},
  journaltitle = {PLOS Computational Biology},
  volume = {15},
  number = {1},
  eprint = {30629591},
  eprinttype = {pmid},
  doi = {10.1371/journal.pcbi.1006286},
  abstract = {The high failure rate of therapeutics showing promise in mouse models to translate to patients is a pressing challenge in biomedical science. Though retrospective studies have examined the fidelity of mouse models to their respective human conditions, approaches for prospective translation of insights from mouse models to patients remain relatively unexplored. Here, we develop a semi-supervised learning approach for inference of disease-associated human differentially expressed genes and pathways from mouse model experiments. We examined 36 transcriptomic case studies where comparable phenotypes were available for mouse and human inflammatory diseases and assessed multiple computational approaches for inferring human biology from mouse datasets. We found that semi-supervised training of a neural network identified significantly more true human biological associations than interpreting mouse experiments directly. Evaluating the experimental design of mouse experiments where our model was most successful revealed principles of experimental design that may improve translational performance. Our study shows that when prospectively evaluating biological associations in mouse studies, semi-supervised learning approaches, combining mouse and human data for biological inference, provide the most accurate assessment of human in vivo disease processes. Finally, we proffer a delineation of four categories of model system-to-human “Translation Problems” defined by the resolution and coverage of the datasets available for molecular insight translation and suggest that the task of translating insights from model systems to human disease contexts may be better accomplished by a combination of translation-minded experimental design and computational approaches.},
  pmcid = {6343937},
  annotation = {MAG ID: 2909372163 S2ID: bc83644dbe87700685cad6c7fd8a65df15bbb145}
}

@article{cai.etal_2010,
  title = {Is Human Blood a Good Surrogate for Brain Tissue in Transcriptional Studies?},
  author = {Cai, Chaochao and Langfelder, Peter and Fuller, Tova F. and Oldham, Michael C. and Luo, Rui and van den Berg, Leonard H. and Ophoff, Roel A. and Horvath, Steve},
  options = {useprefix=true},
  date = {2010-10-20},
  journaltitle = {BMC Genomics},
  shortjournal = {BMC Genomics},
  volume = {11},
  number = {1},
  pages = {589},
  issn = {1471-2164},
  doi = {10.1186/1471-2164-11-589},
  url = {https://doi.org/10.1186/1471-2164-11-589},
  urldate = {2022-09-06},
  abstract = {Since human brain tissue is often unavailable for transcriptional profiling studies, blood expression data is frequently used as a substitute. The underlying hypothesis in such studies is that genes expressed in brain tissue leave a transcriptional footprint in blood. We tested this hypothesis by relating three human brain expression data sets (from cortex, cerebellum and caudate nucleus) to two large human blood expression data sets (comprised of 1463 individuals).},
  keywords = {Brain Module,Caudate Nucleus,Module Membership,Module Preservation,Preserve Module},
  file = {C\:\\Users\\nov18\\Zotero\\storage\\I4H5T5LF\\Cai et al_2010_Is human blood a good surrogate for brain tissue in transcriptional studies.pdf;C\:\\Users\\nov18\\Zotero\\storage\\TKQF2NP3\\1471-2164-11-589.html}
}

@article{domenicobenvenuto.etal_2022,
  title = {The Evolution of {{Monkeypox}} Virus: A Genetic and Structural Analysis Reveals Mutations in Proteins Involved in Host-Pathogen Interaction},
  author = {{Domenico Benvenuto} and {Serena Vita} and Pascarella, Stefano and {Martina Bianchi} and {Marta Giovanetti} and {Roberto Cauda} and Nicastri, Emanuele and {Antonio Cassone} and {Massimo Ciccozzi}},
  date = {2022-06-22},
  journaltitle = {bioRxiv},
  doi = {10.1101/2022.06.22.497195},
  abstract = {Background: Over the past few months, we have witnessed a new outbreak of a MPXV that has been detected without a clear link to Africa and has quickly spread globally. Methods: In this article we investigate the mutational pattern of the MPXV and provide evidence for the presence of 6 new mutations that appear to characterize the current MPX-2022 outbreak. With the use of a number of chemical and physical parameters, we predict the stability of the mutated proteins, and propose an interpretation of the impact of these mutations on viral fitness). Findings: Most mutations, particularly the Immunomodulator A46, TNFr and Large transcript constituent, affect proteins playing an important role in host response to MPVX infection and could also be relevant to the clinical features of the 2022 MPXV outbreak. Interpretation: Although further, experimental work is necessary for a full understanding of the impact of the mutations here reported on virus replication pathways and host immunomodulation, our in-silico data suggest the importance of monitoring the emergence of new MPXV mutations for the prevention of future outbreaks potentially dangerous for public health. Funding: No funding to declare.},
  annotation = {MAG ID: 4283397790 S2ID: 47d769cb51666f20b0d68ee923644e50040096d8}
}

@article{gurbuzbalaban.etal_2015,
  title = {Why {{Random Reshuffling Beats Stochastic Gradient Descent}}},
  author = {Gurbuzbalaban, Mert and Ozdaglar, Asuman and Ozdaglar, Asu and Parrilo, Pablo A.},
  date = {2015-10-29},
  journaltitle = {Mathematical Programming},
  doi = {10.1007/s10107-019-01440-w},
  abstract = {We analyze the convergence rate of the random reshuffling (RR) method, which is a randomized first-order incremental algorithm for minimizing a finite sum of convex component functions. RR proceeds in cycles, picking a uniformly random order (permutation) and processing the component functions one at a time according to this order, i.e., at each cycle, each component function is sampled without replacement from the collection. Though RR has been numerically observed to outperform its with-replacement counterpart stochastic gradient descent (SGD), characterization of its convergence rate has been a long standing open question. In this paper, we answer this question by showing that when the component functions are quadratics or smooth and the sum function is strongly convex, RR with iterate averaging and a diminishing stepsize \$\textbackslash alpha\_k=\textbackslash Theta(1/k\^s)\$ for \$s\textbackslash in (1/2,1)\$ converges at rate \$\textbackslash Theta(1/k\^\{2s\})\$ with probability one in the suboptimality of the objective value, thus improving upon the \$\textbackslash Omega(1/k)\$ rate of SGD. Our analysis draws on the theory of Polyak-Ruppert averaging and relies on decoupling the dependent cycle gradient error into an independent term over cycles and another term dominated by \$\textbackslash alpha\_k\^2\$. This allows us to apply law of large numbers to an appropriately weighted version of the cycle gradient errors, where the weights depend on the stepsize. We also provide high probability convergence rate estimates that shows decay rate of different terms and allows us to propose a modification of RR with convergence rate \$\{\textbackslash cal O\}(\textbackslash frac\{1\}\{k\^2\})\$.},
  annotation = {ARXIV\_ID: 1510.08560 MAG ID: 3098249575 S2ID: 0e4ae5ca700eba96e34190f75c02b0ad4ebd958c}
}

@article{huang_2017,
  title = {Imitating the Brain with Neurocomputer a “New” Way towards Artificial General Intelligence},
  author = {Huang, Tiejun},
  date = {2017-10-01},
  journaltitle = {International Journal of Automation and Computing},
  volume = {14},
  number = {5},
  pages = {520--531},
  doi = {10.1007/s11633-017-1082-y},
  abstract = {To achieve the artificial general intelligence (AGI), imitate the intelligence? or imitate the brain? This is the question! Most artificial intelligence (AI) approaches set the understanding of the intelligence principle as their premise. This may be correct to implement specific intelligence such as computing, symbolic logic, or what the AlphaGo could do. However, this is not correct for AGI, because to understand the principle of the brain intelligence is one of the most difficult challenges for our human beings. It is not wise to set such a question as the premise of the AGI mission. To achieve AGI, a practical approach is to build the so-called neurocomputer, which could be trained to produce autonomous intelligence and AGI. A neurocomputer imitates the biological neural network with neuromorphic devices which emulate the bio-neurons, synapses and other essential neural components. The neurocomputer could perceive the environment via sensors and interact with other entities via a physical body. The philosophy under the “new” approach, so-called as imitationalism in this paper, is the engineering methodology which has been practiced for thousands of years, and for many cases, such as the invention of the first airplane, succeeded. This paper compares the neurocomputer with the conventional computer. The major progress about neurocomputer is also reviewed.},
  annotation = {MAG ID: 2617697564}
}

@article{jing.etal_2022,
  title = {Modelling the Geographical Spread of {{HIV}} among {{MSM}} in {{Guangdong}}, {{China}}: A Metapopulation Model Considering the Impact of Pre-Exposure Prophylaxis.},
  author = {Jing, Fengshi and {Yang Ye} and {Yi Zhou} and {Hanchu Zhou} and {Zhongzhi Xu} and Lu, Ying and {Xiaoyu Tao} and {Shujuan Yang} and Cheng, Weibin and Tian, Junzhang and Tang, Weiming and Wu, Dan},
  date = {2022-01-10},
  journaltitle = {Philosophical Transactions of the Royal Society A},
  volume = {380},
  number = {2214},
  eprint = {34802265},
  eprinttype = {pmid},
  pages = {20210126},
  doi = {10.1098/rsta.2021.0126},
  abstract = {Men who have sex with men (MSM) make up the majority of new human immunodeficiency virus (HIV) diagnoses among young people in China. Understanding HIV transmission dynamics among the MSM population is, therefore, crucial for the control and prevention of HIV infections, especially for some newly reported genotypes of HIV. This study presents a metapopulation model considering the impact of pre-exposure prophylaxis (PrEP) to investigate the geographical spread of a hypothetically new genotype of HIV among MSM in Guangdong, China. We use multiple data sources to construct this model to characterize the behavioural dynamics underlying the spread of HIV within and between 21 prefecture-level cities (i.e. Guangzhou, Shenzhen, Foshan, etc.) in Guangdong province: the online social network via a gay social networking app, the offline human mobility network via the Baidu mobility website, and self-reported sexual behaviours among MSM. Results show that PrEP initiation exponentially delays the occurrence of the virus for the rest of the cities transmitted from the initial outbreak city; hubs on the movement network, such as Guangzhou, Shenzhen, and Foshan are at a higher risk of 'earliest' exposure to the new HIV genotype; most cities acquire the virus directly from the initial outbreak city while others acquire the virus from cities that are not initial outbreak locations and have relatively high betweenness centralities, such as Guangzhou, Shenzhen and Shantou. This study provides insights in predicting the geographical spread of a new genotype of HIV among an MSM population from different regions and assessing the importance of prefecture-level cities in the control and prevention of HIV in Guangdong province. This article is part of the theme issue 'Data science approach to infectious disease surveillance'.},
  annotation = {MAG ID: 3214788327 S2ID: f0ae96a7bd078ffbe3b8ef53f9707d72e85044e4}
}

@article{lotfollahi.etal_2020,
  title = {Conditional Out-of-Distribution Generation for Unpaired Data Using Transfer {{VAE}}.},
  author = {Lotfollahi, Mohammad and Naghipourfar, Mohsen and Theis, Fabian J. and Theis, Fabian J. and Wolf, F. Alexander},
  date = {2020},
  journaltitle = {Bioinformatics},
  volume = {36},
  eprint = {33381839},
  eprinttype = {pmid},
  doi = {10.1093/bioinformatics/btaa800},
  abstract = {MOTIVATION While generative models have shown great success in sampling high-dimensional samples conditional on low-dimensional descriptors (stroke thickness in MNIST, hair color in CelebA, speaker identity in WaveNet), their generation out-of-distribution poses fundamental problems due to the difficulty of learning compact joint distribution across conditions. The canonical example of the conditional variational autoencoder (CVAE), for instance, does not explicitly relate conditions during training and, hence, has no explicit incentive of learning such a compact representation. RESULTS We overcome the limitation of the CVAE by matching distributions across conditions using maximum mean discrepancy in the decoder layer that follows the bottleneck. This introduces a strong regularization both for reconstructing samples within the same condition and for transforming samples across conditions, resulting in much improved generalization. As this amount to solving a style-transfer problem, we refer to the model as transfer VAE (trVAE). Benchmarking trVAE on high-dimensional image and single-cell RNA-seq, we demonstrate higher robustness and higher accuracy than existing approaches. We also show qualitatively improved predictions by tackling previously problematic minority classes and multiple conditions in the context of cellular perturbation response to treatment and disease based on high-dimensional single-cell gene expression data. For generic tasks, we improve Pearson correlations of high-dimensional estimated means and variances with their ground truths from 0.89 to 0.97 and 0.75 to 0.87, respectively. We further demonstrate that trVAE learns cell-type-specific responses after perturbation and improves the prediction of most cell-type-specific genes by 65\%. AVAILABILITY AND IMPLEMENTATION The trVAE implementation is available via github.com/theislab/trvae. The results of this article can be reproduced via github.com/theislab/trvae\_reproducibility.},
  annotation = {MAG ID: 3117464799 S2ID: fc8bfaa15a5fb235520d0eba5c752875a7535cd6}
}

@article{mourragui.etal_2019,
  title = {{{PRECISE}}: {{A}} Domain Adaptation Approach to Transfer Predictors of Drug Response from Pre-Clinical Models to Tumors},
  author = {Mourragui, Soufiane and Loog, Marco and Loog, Marco and {Marcel J. T. Reinders} and Reinders, Marcel J. T. and Wessels, Lodewyk F. A.},
  date = {2019-02-15},
  journaltitle = {bioRxiv},
  eprint = {31510654},
  eprinttype = {pmid},
  pages = {536797},
  doi = {10.1101/536797},
  abstract = {Motivation: Cell lines and patient-derived xenografts (PDX) have been used extensively to understand the molecular underpinnings of cancer. While core biological processes are typically conserved, these models also show important differences compared to human tumors, hampering the translation of findings from pre-clinical models to the human setting. In particular, employing drug response predictors generated on data derived from pre-clinical models to predict patient response, remains a challenging task. As very large drug response datasets have been collected for pre-clinical models, and patient drug response data is often lacking, there is an urgent need for methods that efficiently transfer drug response predictors from pre-clinical models to the human setting. Results: We show that cell lines and PDXs share common characteristics and processes with human tumors. We quantify this similarity and show that a regression model cannot simply be trained on cell lines or PDXs and then applied on tumors. We developed PRECISE, a novel methodology based on domain adaptation that captures the common information shared amongst pre-clinical models and human tumors in a consensus representation. Employing this representation, we train predictors of drug response on pre-clinical data and apply these predictors to stratify human tumors. We show that the resulting domain-invariant predictors show a small reduction in predictive performance in the pre-clinical domain but, importantly, reliably recover known associations between independent biomarkers and their companion drugs on human tumors.},
  pmcid = {6612899},
  annotation = {MAG ID: 2913611220 S2ID: 02a3f03af9b0fa05a786cb3a9e9f8f3a4e184bac},
  file = {C\:\\Users\\nov18\\Zotero\\storage\\LQEJSRIH\\Mourragui et al_2019_PRECISE.pdf}
}

@article{ruder_2016,
  title = {An Overview of Gradient Descent Optimization Algorithms},
  author = {Ruder, Sebastian},
  date = {2016-09-15},
  journaltitle = {arXiv: Learning},
  abstract = {Gradient descent optimization algorithms, while increasingly popular, are often used as black-box optimizers, as practical explanations of their strengths and weaknesses are hard to come by. This article aims to provide the reader with intuitions with regard to the behaviour of different algorithms that will allow her to put them to use. In the course of this overview, we look at different variants of gradient descent, summarize challenges, introduce the most common optimization algorithms, review architectures in a parallel and distributed setting, and investigate additional strategies for optimizing gradient descent.},
  annotation = {ARXIV\_ID: 1609.04747 MAG ID: 2523246573 S2ID: 769ef3d5021cd71c37d2c403f231a53d1accf786}
}

@article{sankaran.etal_2021,
  title = {Predictive {{Modeling}} of the {{Spread}} of {{COVID-19}}: {{The Case}} of {{India}}},
  author = {Sankaran, Sriram and Mohan, Vamshi Sunku and Seshadrinath, Mukund and Gouda, K. C. and Shivappa, Himesh and Achuthan, Krishnashree},
  date = {2021-03-13},
  journaltitle = {Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering},
  volume = {383},
  pages = {131--149},
  doi = {10.1007/978-3-030-79276-3_11},
  abstract = {COVID-19 has been the most notorious pandemic affecting the entire world resulting in numerous deaths thus crippling the world economy. While vaccines are in the process of being developed for protection, countries are implementing measures such as social distancing to prevent the spread of the virus. Also, there exists a need for developing mathematical models to predict the rate of spread of COVID-19 and quantify its impact on countries such as India. Towards this goal, we developed a realistic COVID-19 dataset consisting of state-wide distribution of number of cases in India from March-July 2020. Further, we conduct exploratory data analysis on the dataset to understand the states and their corresponding growth rates. This enables us to cluster states with exponential and non-exponential growth rates as well as assess the effectiveness of lockdown imposed to curb the spread of virus. Finally, we develop predictive models using Auto-Regressive Integrated Moving Average (ARIMA) and Long Short-Term Memory Networks (LSTM) on time-series data for top-10 affected states in India to predict the rate of spread and validate their accuracy. Finally, our models can be used to guide the development of mechanisms for optimal resource allocation of healthcare systems and response.},
  annotation = {MAG ID: 3185479852 S2ID: d89e289ae991d19583be14b70573d6c9d4c1b508}
}

@article{saturi_2020,
  title = {Development of {{Prediction}} and {{Forecasting Model}} for {{Dengue Disease}} Using {{Machine Learning Algorithms}}},
  author = {Saturi, Swapna},
  date = {2020},
  journaltitle = {2020 IEEE International Conference on Distributed Computing, VLSI, Electrical Circuits and Robotics (DISCOVER)},
  doi = {10.1109/discover50404.2020.9278079},
  abstract = {Globally, Dengue is one of the most quickly spreading vector-borne viral sicknesses with an expanding number of territories in danger. Many researchers have worked on different measures to control and prevent the spread of disease. The main objective of the research is to develop a forecast model to control the outbreak of dengue disease that will give an opportunity for medical professionals in designing, planning and handling the disease at an early stage. Moreover, the improvement of the assortment of strategies for determining and predictive modeling utilizing measurable, numerical examination of machine learning was studied. There are mainly six issues need to be solved in determination of dengue disease, those are exploring data sources, analyzing data sources, techniques for data preparation, data representation, dengue forecasting models and evaluation approaches. A major limitation of the traditional methods is that these methods need large volumes of data for data processing, to improve the dynamic characteristics. From the review of existing methods, it can be clearly stated that the K-means clustering method with fuzzy based system has high accuracy and it significantly improves the analysis/prediction of dengue disease. The k-means clustering algorithm separates the dengue diseased patient records into k divisions. As the dengue dataset were fully clustered, k-means clustering method improves the analysis or prediction of dengue disease. Similarly, the fuzzy based system The input factors and changing over these informational factors into fuzzy membership functions will make a better decision making in predicting dengue forecasting model. Thus, the issues stated from comprehensive research provide a useful platform for public health research and epidemiology.},
  annotation = {MAG ID: 3116163045 S2ID: b18d791c6d3d588cdd7e3db8061ae417f5e71f1d}
}

@article{sharifi-noghabi.etal_2020,
  title = {{{AITL}}: {{Adversarial Inductive Transfer Learning}} with Input and Output Space Adaptation for Pharmacogenomics},
  author = {Sharifi-Noghabi, Hossein and Noghabi, Hossein Sharifi and Peng, Shuman and Zolotareva, Olga and Collins, Colin and Ester, Martin},
  date = {2020-01-25},
  journaltitle = {bioRxiv},
  eprint = {32657371},
  eprinttype = {pmid},
  doi = {10.1101/2020.01.24.918953},
  abstract = {Motivation: the goal of pharmacogenomics is to predict drug response in patients using their single- or multi-omics data. A major challenge is that clinical data (i.e. patients) with drug response outcome is very limited, creating a need for transfer learning to bridge the gap between large pre-clinical pharmacogenomics datasets (e.g. cancer cell lines), as a source domain, and clinical datasets as a target domain. Two major discrepancies exist between pre-clinical and clinical datasets: 1) in the input space, the gene expression data due to difference in the basic biology, and 2) in the output space, the different measures of the drug response. Therefore, training a computational model on cell lines and testing it on patients violates the i.i.d assumption that train and test data are from the same distribution.  Results: We propose Adversarial Inductive Transfer Learning (AITL), a deep neural network method for addressing discrepancies in input and output space between the pre-clinical and clinical datasets. AITL takes gene expression of patients and cell lines as the input, employs adversarial domain adaptation and multi-task learning to address these discrepancies, and predicts the drug response as the output. To the best of our knowledge, AITL is the first adversarial inductive transfer learning method to address both input and output discrepancies. Experimental results indicate that AITL outperforms state-of-the-art pharmacogenomics and transfer learning baselines and may guide precision oncology more accurately.},
  pmcid = {7355265},
  annotation = {MAG ID: 3002752511 S2ID: eebae70a6aebcc9bcd74e717fed5b655487f1245}
}

@article{sitaram.etal_2017,
  title = {Closed-Loop Brain Training: The Science of Neurofeedback},
  author = {Sitaram, Ranganatha and Ros, Tomas and Stoeckel, Luke E. and Haller, Sven and Scharnowski, Frank and Lewis-Peacock, Jarrod A. and Weiskopf, Nikolaus and Blefari, Maria Laura and Rana, Mohit and Oblak, Ethan and Birbaumer, Niels and Sulzer, James},
  date = {2017-02-01},
  journaltitle = {Nature Reviews Neuroscience},
  volume = {18},
  number = {2},
  eprint = {28003656},
  eprinttype = {pmid},
  doi = {10.1038/nrn.2016.164},
  abstract = {Neurofeedback is a psychophysiological procedure in which online feedback of neural activation is provided to the participant for the purpose of self-regulation. Learning control over specific neur ...},
  annotation = {MAG ID: 2566775857}
}

@article{tinawi_,
  title = {Machine {{Learning}} for {{Time Series Anomaly Detection}}},
  author = {Tinawi, Ihssan},
  pages = {55},
  abstract = {In this thesis, I explored machine learning and other statistical techniques for anomaly detection on time series data obtained from Internet-of-Things sensors. The data, obtained from satellite telemetry signals, were used to train models to forecast a signal based on its historic patterns. When the prediction passed a dynamic error threshold, then that point was flagged as anomalous. I used multiple models such as Long Short-Term Memory (LSTM), autoregression, Multi-Layer Perceptron, and Encoder-Decoder LSTM.},
  langid = {english},
  file = {C\:\\Users\\nov18\\Dropbox\\PC\\Downloads\\tinawi_ - Extracted Annotations (2282022, 114236 AM).md;C\:\\Users\\nov18\\Dropbox\\PC\\Downloads\\undefined - Extracted Annotations (342022, 74831 PM).md;C\:\\Users\\nov18\\Zotero\\storage\\KBLMD2YA\\Tinawi - Machine Learning for Time Series Anomaly Detection.pdf}
}

@article{vistro.etal_2021,
  title = {Predicting {{Growth}} and {{Trends}} of {{COVID-19}} by {{Implementing Machine Learning Algorithms}}},
  author = {Vistro, Daniel Mago and {Muhammad Shoaib Farooq} and Farooq, Muhammad and Rehman, Attique Ur and {Attique Ur Rehman} and {Muhammad Omer Aftab}},
  date = {2021-09-13},
  journaltitle = {Proceedings of the 3rd International Conference on Integrated Intelligent Computing Communication \& Security (ICIIC 2021)},
  volume = {3},
  number = {3},
  pages = {587--595},
  doi = {10.2991/ahis.k.210913.075},
  abstract = {Artificial Intelligence has absolutely revolutionized the world in which we live, and with the passing of time it advances exponentially. The applications of AI are tremendous like healthcare and medical solutions, disease diagnostics, agriculture, developing security infrastructures, Autonomous vehicles, intelligent systems, industrial manufacturing, robotics and so much more. COVID19 is a deadly virus that started from china in 2019 and started to spread rapidly and within time spread throughout various countries of world and in 2020 the world went to a huge pandemic and many lives were lost due to this deadly virus causing to a major health hazard. Moreover, in 2021 many countries experience other new forms of the Covid19 that are faster to spread and more deadly. The spread and growth need to me monitored and evaluated to control the spread. The paper states the proposed methodology to evaluate insights of the growth rate or number of cases along with the death rate of COVID19 to getter better visualization to impose lockdown and area evacuation for population safety. Moreover, the technique will help to evaluate the trend to get better insights for behavior analysis of COVID19. This study would aid policymakers in taking the required steps in advance, such as preparing isolation wards, ensuring the supply of drugs and paramedical staff, deciding partial or complete lockdown strategies, recruiting volunteers, and developing economic strategies. Out of all techniques, Random Forest algorithm outstands others with the highest accuracy of 87.28\% with precision and recall of 89\% and 85\% respectively.},
  annotation = {MAG ID: 3201690066 S2ID: 751299664db6daaea9138bb05e9e895ec463805a}
}

@article{wang.etal_2020,
  title = {Prediction of Epidemic Trends in {{COVID-19}} with Logistic Model and Machine Learning Technics},
  author = {Wang, Peipei and Zheng, Xinqi and Li, Jiayang and Zhu, Bangren},
  date = {2020-10-01},
  journaltitle = {Chaos Solitons \& Fractals},
  volume = {139},
  number = {139},
  eprint = {32834611},
  eprinttype = {pmid},
  pages = {110058--110058},
  doi = {10.1016/j.chaos.2020.110058},
  abstract = {Abstract   COVID-19 has now had a huge impact in the world, and more than 8 million people in more than 100 countries are infected. To contain its spread, a number of countries published control measures. However, itâs not known when the epidemic will end in global and various countries. Predicting the trend of COVID-19 is an extremely important challenge. We integrate the most updated COVID-19 epidemiological data before June 16, 2020 into the Logistic model to fit the cap of epidemic trend, and then feed the cap value into Fbprophet model, a machine learning based time series prediction model to derive the epidemic curve and predict the trend of the epidemic. Three significant points are summarized from our modeling results for global, Brazil, Russia, India, Peru and Indonesia. Under mathematical estimation, the global outbreak will peak in late October, with an estimated 14.12 million people infected cumulatively.},
  pmcid = {7328553},
  annotation = {MAG ID: 3039033741},
  file = {C\:\\Users\\nov18\\Zotero\\storage\\WUPG4LJE\\Wang et al_2020_Prediction of epidemic trends in COVID-19 with logistic model and machine.pdf}
}

@article{ziyichen.etal_2021,
  title = {Escaping {{Saddle Points}} in {{Nonconvex Minimax Optimization}} via {{Cubic-Regularized Gradient Descent-Ascent}}},
  author = {{Ziyi Chen} and {Qunwei Li} and {Yi Zhou}},
  date = {2021},
  journaltitle = {ArXiv},
  abstract = {The gradient descent-ascent (GDA) algorithm has been widely applied to solve nonconvex minimax optimization problems. However, the existing GDA-type algorithms can only find first-order stationary points of the envelope function of nonconvex minimax optimization problems, which does not rule out the possibility to get stuck at suboptimal saddle points. In this paper, we develop Cubic-GDA – the first GDA-type algorithm for escaping strict saddle points in nonconvex-stronglyconcave minimax optimization. Specifically, the algorithm uses gradient ascent to estimate the second-order information of the minimax objective function, and it leverages the cubic regularization technique to efficiently escape the strict saddle points. Under standard smoothness assumptions on the objective function, we show that Cubic-GDA admits an intrinsic potential function whose value monotonically decreases in the minimax optimization process. Such a property leads to a desired global convergence of Cubic-GDA to a second-order stationary point at a sublinear rate. Moreover, we analyze the convergence rate of Cubic-GDA in the full spectrum of a gradient dominant-type nonconvex geometry. Our result shows that Cubic-GDA achieves an orderwise faster convergence rate than the standard GDA for a wide spectrum of gradient dominant geometry. Our study bridges minimax optimization with second-order optimization and may inspire new developments along this direction.},
  annotation = {S2ID: e4080ab44fbac59f0d1820d77d5125b8647d06fb}
}

@article{zorins.grabusts_2015,
  title = {Artificial {{Neural Networks}} and {{Human Brain}}: {{Survey}} of {{Improvement Possibilities}} of {{Learning}}},
  author = {Zorins, Aleksejs and Grabusts, Peteris},
  date = {2015-06-16},
  volume = {3},
  pages = {228--231},
  doi = {10.17770/etr2015vol3.165},
  abstract = {There are numerous applications of Artificial Neural Networks (ANN) at the present time and there are different learning algorithms, topologies, hybrid methods etc. It is strongly believed that ANN is built using human brain’s functioning principles but still ANN is very primitive and tricky way for real problem solving. In the recent years modern neurophysiology advanced to a big extent in understanding human brain functions and structure, however, there is a lack of this knowledge application to real ANN learning algorithms. Each learning algorithm and each network topology should be carefully developed to solve more or less complex problem in real life. One may say that almost each serious application requires its own network topology, algorithm and data pre-processing. This article presents a survey of several ways to improve ANN learning possibilities according to human brain structure and functioning, especially one example of this concept – neuroplasticity – automatic adaptation of ANN topology to problem domain.},
  annotation = {MAG ID: 1502661011},
  file = {C\:\\Users\\nov18\\Zotero\\storage\\LB2ZMSU9\\Zorins and Grabusts - 2015 - Artificial Neural Networks and Human Brain Survey.pdf}
}


