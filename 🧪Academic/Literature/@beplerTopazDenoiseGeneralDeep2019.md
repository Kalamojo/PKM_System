---
aliases:
  - "Topaz-Denoise: General deep denoising models for cryoEM"
authors: Tristan Bepler, Tristan Bepler, Alex J. Noble, Bonnie Berger
year: 2019
type:
  - paper
tags:
  - academic
page(s): "838920"
---
> [!abstract]
> Cryo-electron microscopy (cryoEM) is becoming the preferred method for resolving protein structure. Low signal-to-noise (SNR) in cryoEM images reduces the confidence and throughput of structure determination during several steps of data processing, resulting in impediments such as missing particle orientations. Denoising cryoEM images can not only improve downstream analysis but also accelerate the time-consuming data collection process by allowing lower electron dose micrographs to be used for analysis without compromising structural interpretability. Here, we present Topaz-Denoise, a deep learning method for reliably increasing the SNR of cryoEM images in seconds. By training on a dataset composed of thousands of micrographs collected across a wide range of imaging conditions, we are able to learn models capturing the complexity of the cryoEM image formation process. While this general idea has been deployed successfully in natural imaging, protein threading, and proteomics, it has yet to be applied systematically in cryoEM where the lack of ground truth signal has been a long-standing limitation. To address this, we make the key insight that forming paired, independent micrographs from even and odd camera movie frames enables us to train denoising models without observing ground truth signal. We demonstrate that our denoising model improves SNR by roughly 100x over raw micrographs and 1.8x over other methods. Notably, we show that denoising with our general model enables solving the first 3D single particle structure of clustered protocadherin, an elongated particle with previously-elusive views. Topaz-Denoise and pre-trained general models are now included in Topaz (https://github.com/tbepler/topaz), a free and open-source software package that focuses on particle picking, and has been integrated into the Appion cryoEM suite. We expect that Topaz-Denoise will be of broad utility to the cryoEM community for improving micrograph interpretability and accelerating analysis.

# Annotations  
(8/11/2023, 9:19:38 PM)

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FWF5GTJNC%22%2C%22annotationKey%22%3A%22R3695F6Z%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B254.694%2C608.92%2C486.884%2C621.203%5D%2C%5B72%2C593.92%2C498.517%2C606.203%5D%2C%5B72%2C578.92%2C389.761%2C591.203%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FG5N9U32C%22%5D%2C%22locator%22%3A%221%22%7D%7D">“Denoising cryoEM images can not only improve downstream analysis but also accelerate the time-consuming data collection process by allowing lower electron dose micrographs to be used for analysis.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FG5N9U32C%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Bepler et al., 2019, p. 1</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FWF5GTJNC%22%2C%22annotationKey%22%3A%22H7AZ2TMS%22%2C%22color%22%3A%22%23a28ae5%22%2C%22pageLabel%22%3A%221%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B72%2C563.92%2C529.083%2C576.203%5D%2C%5B72%2C548.92%2C224.739%2C561.203%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FG5N9U32C%22%5D%2C%22locator%22%3A%221%22%7D%7D">“Topaz-Denoise, a deep learning method for reliably and rapidly increasing the SNR of cryoEM images and cryoET tomograms”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FG5N9U32C%22%5D%2C%22locator%22%3A%221%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Bepler et al., 2019, p. 1</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FWF5GTJNC%22%2C%22annotationKey%22%3A%22BHVNWX2G%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B274.245%2C494.92%2C529.669%2C507.203%5D%2C%5B72%2C479.92%2C481.429%2C492.203%5D%2C%5B72%2C464.501%2C421.539%2C477.407%5D%2C%5B421.491%2C470.1%2C430.663%2C477.847%5D%2C%5B430.662%2C464.92%2C433.717%2C477.203%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FG5N9U32C%22%5D%2C%22locator%22%3A%222%22%7D%7D">“However, these methods do not address the specific noise properties of micrographs and often do not provide interpretable results, which increasingly hinders attempts to resolve small and non-globular proteins​ 4,5​ .”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FG5N9U32C%22%5D%2C%22locator%22%3A%222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Bepler et al., 2019, p. 2</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FWF5GTJNC%22%2C%22annotationKey%22%3A%2246JGGBKN%22%2C%22color%22%3A%22%235fb236%22%2C%22pageLabel%22%3A%222%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B447.782%2C254.92%2C538.238%2C267.847%5D%2C%5B72%2C239.92%2C528.453%2C252.203%5D%2C%5B72%2C224.92%2C351.277%2C237.203%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FG5N9U32C%22%5D%2C%22locator%22%3A%222%22%7D%7D">“a general machine learning (ML) framework, called Noise2Noise, for learning denoising models from paired noisy images rather than paired noisy and ground truth images.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FG5N9U32C%22%5D%2C%22locator%22%3A%222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Bepler et al., 2019, p. 2</span>)</span>

<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FG5N9U32C%22%5D%2C%22locator%22%3A%222%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Bepler et al., 2019, p. 2</span>)</span> Noise2Noise works by taking a noisy image, applying additional random noise to create a pair of variations, and then training a deep neural network to generate a new image that minimizes the difference between itself and both extra-noisy images.

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FWF5GTJNC%22%2C%22annotationKey%22%3A%22B26FPAWM%22%2C%22color%22%3A%22%23ff6666%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B407.463%2C707.17%2C527.216%2C719.453%5D%2C%5B72%2C692.17%2C524.141%2C704.453%5D%2C%5B72%2C677.17%2C507.159%2C689.453%5D%2C%5B72%2C662.17%2C353.69%2C674.453%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FG5N9U32C%22%5D%2C%22locator%22%3A%223%22%7D%7D">“We make the key insight that the individual movie frames collected by modern direct detector devices (DDD) are many independent observations of the same underlying signal and, hence, can be used to learn denoising models directly via the Noise2Noise framework.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FG5N9U32C%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Bepler et al., 2019, p. 3</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FWF5GTJNC%22%2C%22annotationKey%22%3A%22ANQLA3NI%22%2C%22color%22%3A%22%23e56eee%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B435.53%2C602.17%2C503.382%2C614.453%5D%2C%5B72%2C586.751%2C251.652%2C599.657%5D%2C%5B251.627%2C587.17%2C534.507%2C600.097%5D%2C%5B72%2C572.17%2C521.772%2C584.453%5D%2C%5B72%2C557.17%2C177.73%2C569.453%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FG5N9U32C%22%5D%2C%22locator%22%3A%223%22%7D%7D">“use denoising combined with Topaz particle picking​ 16​ to obtain the first 3D single particle cryoEM structures of clustered protocadherin, an elongated particle with previously-elusive views and a previously unseen conformation.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FG5N9U32C%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Bepler et al., 2019, p. 3</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FWF5GTJNC%22%2C%22annotationKey%22%3A%22BS2UFPV4%22%2C%22color%22%3A%22%23e56eee%22%2C%22pageLabel%22%3A%223%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B282.195%2C497.17%2C532.752%2C509.453%5D%2C%5B72%2C482.17%2C366.473%2C494.453%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FG5N9U32C%22%5D%2C%22locator%22%3A%223%22%7D%7D">“we develop the first general 3D denoising model for cryoET tomograms, trained on dozens of cryoET tomograms”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FG5N9U32C%22%5D%2C%22locator%22%3A%223%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Bepler et al., 2019, p. 3</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FWF5GTJNC%22%2C%22annotationKey%22%3A%22KP826BXZ%22%2C%22color%22%3A%22%23f19837%22%2C%22pageLabel%22%3A%2211%22%2C%22position%22%3A%7B%22pageIndex%22%3A11%2C%22rects%22%3A%5B%5B276.699%2C647.17%2C526.575%2C659.453%5D%2C%5B72%2C632.17%2C527.866%2C644.453%5D%2C%5B72%2C617.17%2C536.434%2C629.453%5D%2C%5B72%2C602.17%2C514.406%2C614.453%5D%2C%5B72%2C587.17%2C531.537%2C599.453%5D%2C%5B72%2C572.17%2C378.107%2C584.453%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FG5N9U32C%22%5D%2C%22locator%22%3A%2211%22%7D%7D">“the issue here is two-fold: 1) cryoEM/ET refinement and reconstruction software assume noise distributions typical of raw data, not denoised data, and 2) denoised particles may present hallucinated information from the denoising model that is not detectable by visual inspection. For these reasons, we recommend that Topaz-Denoise models be used to assist with visualization and object identification, then the objects of interest be extracted and processed from raw micrographs/tomograms.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FG5N9U32C%22%5D%2C%22locator%22%3A%2211%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Bepler et al., 2019, p. 11</span>)</span>

<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F12154261%2Fitems%2FG5N9U32C%22%5D%2C%22locator%22%3A%2219%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Bepler et al., 2019, p. 19</span>)</span> To obtain variations of a microgram, movie frames from standard cryo electron microscopy (cryoEM) are used. They are then separated into an "even" and "odd" group. Each "odd" frame is summed together, as well as the "even" frames, and the denoising Deep neural network attempts to denoise each. Loss is calculated by comparing the summed "odd" micrograph with the "denoised" "even" micrograph, and vice versa.]

## References
1. [beplerTopazDenoiseGeneralDeep2019](zotero://select/items/@beplerTopazDenoiseGeneralDeep2019)
